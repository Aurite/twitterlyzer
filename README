This is a RAILS Application that helps you to collect twitter data:

It does the following:

	It uses Delayed Jobs to get things done.
	The Twitter API is wrapped using grackle
	
	Projects
		Persons are organized in projects that contain a set of people

	Persons
		collect one person
		collect multiple persons based on a csv import		
		collect the egonetwork of a given person
		show all people
		show statistics of the people collected (friends, follower distributions, origin etc..)
		
	Connections between persons
		Connections between persons are stored not in the DB but on the HD in  a PStore
		
	Tweets
		collect the tweets of a person
		collect the tweets of all persons
		collects tweets based on a csv list
		collect all retweets of all collected tweets
		export all tweets into a csv		
		show statistics on the tweets (links used, keywords, timeline)
	
	Networks
		export the friendship network of the collected persons in a project the formats:
			UCINET
			Gephi
		export the retweet networks of persons
		export the @ networks between persons
		export the person stats
		export the twitter links of persons

	Tasks	
		It has some onboard scrapers under tasks that scrape the following websites
			Murack.com
			Google
			Twellow
			Wefollow
		
		It can compute some sentiment for german tweets 


The rails app is totally in a beta stadium, has no test coverage!

To get it running you will need to create a :

twitter.yml that contains your twitter credentials
bitly.yml that contains your bitly credentials

see twitter.example.yml or bitly.example.yml for details

Delayed Jobs:
	To start collecting persons or feeds you need to start a couple of delayed job workers:
	To do so use the script "./script/delayed_job -n 4"
	The Benchmarks I measured are depending on the number of workers (n):
		Collecting Tweets: n 4: 40.000 tweets in 10min
				   n 8: 90.000 tweets in 10min
				   n 16: 180.000 tweets in 10 min (70% CPU usage)

		Make sure when your Twitter account is NOT whitelisted that you dont use up your API limitations when using too many workers.
		TODO: Make the workers intelligent and make sure that they only take the job when there is enough API calls left.

