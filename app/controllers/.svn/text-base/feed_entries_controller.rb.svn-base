class FeedEntriesController < ApplicationController
  layout 'default'

  require 'net/http'
  require 'uri'
  require 'rexml/document'

  #API Settings for OPENAMPLIFY
  ApiKey = "s2jhybpryqrr2dzhmu7d8r9jz5e5gmjw"
  ApiPort = 8180
  ApiHost = 'portaltnx.openamplify.com'
  ApiPath = '/AmplifyWeb/AmplifyThis'
    
  # GET /feed_entries
  # GET /feed_entries.xml
  def index
    @project = Project.find(params[:project_id])
    
    #depending if I am showing all entries or only the persons entries.
    if params[:person_id] == nil
      @feed_entries = []
      @grouped_entries = []
      @project.persons.each do |person|
        FeedEntry.find(:all,  :conditions => { :person_id => person}, :order => 'published_at DESC').each do |entry|
          @feed_entries << entry
        end
        FeedEntry.count(:all, :conditions => { :person_id => person}, :order => 'published_at DESC', :group => 'DATE(published_at)').each do |entry|
          @grouped_entries << entry
        end
      end 
    else
      person = params[:person_id]
      @feed_entries = FeedEntry.find(:all,  :conditions => { :person_id => person}, :order => 'published_at DESC')
      @grouped_entries = FeedEntry.count(:all, :conditions => { :person_id => person}, :order => 'published_at DESC', :group => 'DATE(published_at)')
    end
    
    #collect all words of all feeds
    words = ""
    @feed_entries.each do |entry|
      words << " " + entry.text
    end 
    
    #collect word frequencies
    @freqs = word_frequencies(words)
    
    #collect proper nouns
    @proper_nouns = collect_proper_nouns(words)
    
    #create grouped entries by date:
    @grouped_entries = @grouped_entries.sort_by{|x| [x]}
    
    respond_to do |format|
      format.html # index.html.erb
      format.xml  { render :xml => @feed_entries }
    end
  end
  
  def word_frequencies(text)
    #remove urls and username from entries and aggregate to one long text
    URI.extract(text).each do |entry|
      text = text.sub(entry, " ")
    end
        
    #Remove Stopwords
    STOP_WORDS.each do |stopword|  text.gsub!(/(\s|^)#{stopword}\s/i, " ") end
    
    #wordcount
    text = text.split(/[^a-zA-Z]/)
    #text = text.delete("")  
    
    freqs = Hash.new(0)
    text.each { |word| freqs[word] += 1 }
    freqs = freqs.sort_by {|x,y| y }      #sort by highes occurance        

    return freqs
  
  end
  

  # GET /feed_entries/1
  # GET /feed_entries/1.xml
  def show
    @feed_entry = FeedEntry.find(params[:id])

    respond_to do |format|
      format.html # show.html.erb
      format.xml  { render :xml => @feed_entry }
    end
  end

  # GET /feed_entries/new
  # GET /feed_entries/new.xml
  def new
    @feed_entry = FeedEntry.new

    respond_to do |format|
      format.html # new.html.erb
      format.xml  { render :xml => @feed_entry }
    end
  end

  # GET /feed_entries/1/edit
  def edit
    @feed_entry = FeedEntry.find(params[:id])
  end

  # POST /feed_entries
  # POST /feed_entries.xml
  def create
    @feed_entry = FeedEntry.new(params[:feed_entry])

    respond_to do |format|
      if @feed_entry.save
        flash[:notice] = 'FeedEntry was successfully created.'
        format.html { redirect_to(@feed_entry) }
        format.xml  { render :xml => @feed_entry, :status => :created, :location => @feed_entry }
      else
        format.html { render :action => "new" }
        format.xml  { render :xml => @feed_entry.errors, :status => :unprocessable_entity }
      end
    end
  end
  
  #Gather all rss for a given person 
  def collect_all_entries
    person = Person.find(params[:id])
    Delayed::Job.enqueue(CollectAllFeedEntriesJob.new(person.id))

    respond_to do |format|
      format.js do
        render :update do |page|
          flash[:notice] = 'FeedEntries will be collected. Around ' + person.statuses_count.to_s + ' Feed entries will be gathered.'
          page.reload
        end
      end
    end
  end
  
  # PUT /feed_entries/1
  # PUT /feed_entries/1.xml
  def update
    @feed_entry = FeedEntry.find(params[:id])

    respond_to do |format|
      if @feed_entry.update_attributes(params[:feed_entry])
        flash[:notice] = 'FeedEntry was successfully updated.'
        format.html { redirect_to(@feed_entry) }
        format.xml  { head :ok }
      else
        format.html { render :action => "edit" }
        format.xml  { render :xml => @feed_entry.errors, :status => :unprocessable_entity }
      end
    end
  end

  # DELETE /feed_entries/1
  # DELETE /feed_entries/1.xml
  def destroy
    @feed_entry = FeedEntry.find(params[:id])
    @feed_entry.destroy

    respond_to do |format|
      format.html { redirect_to(feed_entries_url) }
      format.xml  { head :ok }
    end
  end
  
  def collect_proper_nouns(text)
    input_type = "inputText"
    URI.extract(text).each do |entry| text = text.sub(entry, "") end
    hash = Hash.new(0)
    begin 
      http = Net::HTTP.new(ApiHost, ApiPort)
      response = http.post(ApiPath, "apiKey=#{ApiKey}&#{input_type}=#{URI::escape(text)}")
      doc= REXML::Document.new(response.read_body)
      proper_nouns = Hash.new(0)    
      values = doc.each_element('//ProperNouns//Topic//Value//text()')
      keys = doc.each_element('//ProperNouns//Topic//Name//text()')
      keys.size.times { |i| hash[ keys[i].to_s ] = values[i].to_s.to_i }
    rescue
      SystemMessage.add_message("error", "Collect Proper Nouns", "Could not establish connection and collect proper nouns.")
    end
    return hash
  end

end
